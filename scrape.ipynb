{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "def scrape_season(start_year, end_year):\n",
    "\n",
    "    season_year = {}\n",
    "\n",
    "    for year in range(start_year,end_year):\n",
    "\n",
    "        #print('Get the colleges from {year} year'.format(year = year))\n",
    "\n",
    "        url = 'https://www.sports-reference.com/cbb/seasons/{year}.html'.format(year = str(year))\n",
    "\n",
    "        # collect HTML data\n",
    "        html = urlopen(url)\n",
    "                \n",
    "        # create beautiful soup object from HTML\n",
    "        soup = BeautifulSoup(html, features=\"html\")\n",
    "\n",
    "        # get table\n",
    "        table = soup.find('table', id='conference-summary')\n",
    "\n",
    "        # Collecting Data\n",
    "        conference_data = []\n",
    "        for row in table.tbody.find_all('tr'):    \n",
    "            # Find all data for each column\n",
    "            rows = row.find_all('td')\n",
    "            conference_data.append(row)\n",
    "\n",
    "        rows_data = [[td.getText().replace('-', ' ') for td in conference_data[i].findAll('td')]\n",
    "                            for i in range(len(conference_data))]\n",
    "\n",
    "        conference_list =[]\n",
    "\n",
    "        for conference in rows_data[0:]:\n",
    "            conference_list.append(conference[0])\n",
    "\n",
    "        hyperlinks_dict = {}\n",
    "        for link in table.tbody.find_all('a'):\n",
    "            if link.get_text() in conference_list:\n",
    "                hyperlinks_dict[link.get_text()] = link.get('href')\n",
    "\n",
    "        \n",
    "        season_dict = {}\n",
    "        season_dict['season'] = hyperlinks_dict\n",
    "        season_year[str(year)] = season_dict\n",
    "\n",
    "    return season_year\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_year = 2021\n",
    "end_year = 2022\n",
    "\n",
    "season_links = scrape_season(start_year, end_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_colleges_links(season_links):\n",
    "\n",
    "    for year in season_links:\n",
    "\n",
    "        for college in season_links[year]['season']:\n",
    "\n",
    "            url = season_links[year]['season'][college]\n",
    "\n",
    "            # collect HTML data\n",
    "            root_link = 'https://www.sports-reference.com'\n",
    "            url = root_link + url\n",
    "            html = urlopen(url)\n",
    "                    \n",
    "            # create beautiful soup object from HTML\n",
    "            soup = BeautifulSoup(html, features=\"html\")\n",
    "\n",
    "            # get table\n",
    "            table = soup.find('table', id='standings')\n",
    "\n",
    "            # Collecting Data\n",
    "            college_data = []\n",
    "            for row in table.tbody.find_all('tr'):    \n",
    "                # Find all data for each column\n",
    "                rows = row.find_all('td')\n",
    "                college_data.append(row)\n",
    "\n",
    "            rows_data = [[td.getText().replace('-', ' ') for td in college_data[i].findAll('td')]\n",
    "                                for i in range(len(college_data))]\n",
    "\n",
    "            college_list =[]\n",
    "\n",
    "            for college in rows_data[0:]:\n",
    "                college_list.append(college[0])\n",
    "\n",
    "            hyperlinks_dict = {}\n",
    "            for link in table.tbody.find_all('a'):\n",
    "                if link.get_text() in college_list:\n",
    "                    hyperlinks_dict[link.get_text()] = link.get('href')\n",
    "\n",
    "\n",
    "            season_links[year]['college'] = hyperlinks_dict\n",
    "  \n",
    "\n",
    "    return season_links\n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_dict = find_colleges_links(season_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Brown': '/cbb/schools/brown/2021.html',\n",
       " 'Columbia': '/cbb/schools/columbia/2021.html',\n",
       " 'Cornell': '/cbb/schools/cornell/2021.html',\n",
       " 'Dartmouth': '/cbb/schools/dartmouth/2021.html',\n",
       " 'Harvard': '/cbb/schools/harvard/2021.html',\n",
       " 'Pennsylvania': '/cbb/schools/pennsylvania/2021.html',\n",
       " 'Princeton': '/cbb/schools/princeton/2021.html',\n",
       " 'Yale': '/cbb/schools/yale/2021.html'}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_dict['2021']['college']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e412bbb8fdd9d6f1dd78a8a239d03e5149c9db982653744ac72765fa6c92c03f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
